# Hish Indexer Configuration
# Copy this file to indexer.env and customize as needed

# === Chunking Configuration ===
# Code chunk sizes (200-400 tokens optimal, Phase 2)
HISH_CODE_CHUNK_SIZE=300
HISH_CODE_CHUNK_OVERLAP=40

# Documentation chunk sizes
HISH_DOCS_CHUNK_SIZE=400
HISH_DOCS_CHUNK_OVERLAP=50

# Tokenizer model for chunking
HISH_TOKENIZER_MODEL=gpt-3.5-turbo

# === Qdrant Configuration ===
# Qdrant server URL
QDRANT_URL=http://localhost:6333

# Collection settings
# Enable scalar int8 quantization (for collections >1M vectors or memory pressure)
# Options: true, false
HISH_ENABLE_QUANTIZATION=false

# === Embedding Model ===
# Model name (must match collection vector name)
HISH_VECTOR_MODEL_NAME=sentence-transformers/paraphrase-multilingual-mpnet-base-v2

# === Search Configuration ===
# Search parameters for pre-prompt hooks
HISH_SEARCH_TOP_K=40
HISH_SEARCH_SCORE_THRESHOLD=0.7
HISH_SEARCH_MAX_RESULTS=20
HISH_MIN_QUERY_LENGTH=3
HISH_QDRANT_TIMEOUT=2

# === Performance Tuning ===
# Batch sizes are auto-detected based on GPU/CPU
# Override only if needed:
# - CPU: 64-128 (default: 128)
# - GPU 4-8GB: 256
# - GPU 8-16GB: 512
# - GPU 16GB+: 1024
# HISH_BATCH_SIZE=128

# === GPU Acceleration ===
# GPU is auto-detected. Set CUDA_VISIBLE_DEVICES to control GPU selection
# CUDA_VISIBLE_DEVICES=0
